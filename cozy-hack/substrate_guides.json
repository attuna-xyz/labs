[
  {
    "content": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\nCTRL K\n\nCTRL K\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nExtract and summarize Hacker News comments\n\n֍\n\nLearn how to extract information (including sentiment analysis) and generate a summary (RAG)\n\nIn this guide, we'll show you how to search Hacker News comments for a topic, extract sentiment, and generate a research summary using Substrate.\n\nThis concise RAG implementation runs dozens of LLM calls in parallel and streams the markdown result. It's easy to remix the runnable TypeScript code below, [hosted on val.town (opens in a new tab)](https://www.val.town/v/substrate/hackerNewsRAG)\n.\n\n  \n\nFirst, we search HackerNews comments using the [Algolia HN Search API (opens in a new tab)](https://hn.algolia.com/api)\n.\n\nTypeScript\n\n``   const searchResults = await hnSearch({    query: query,    numericFilters: `created_at_i>${Math.floor(Date.now() / 1000) - 60 * 60 * 24 * 7 * 4}`,    tags: \"comment\",    });            ``\n\nNext, we use ComputeJSON to extract summary, sentiment, and other metadata from each comment. In TypeScript, we use [zod (opens in a new tab)](https://zod.dev/)\n and [zod-to-json-schema (opens in a new tab)](https://www.npmjs.com/package/zod-to-json-schema)\n to create the JSON schema. In Python, we use [Pydantic (opens in a new tab)](https://docs.pydantic.dev/latest/)\n.\n\nTypeScript\n\nPython\n\n``   const commentInfo = z.object({    summary: z    .string()    .describe(    \"Summarize in a couple sentences: who is commenting, what the comment is about, how it is related to the topic.\",    ),    storyTitle: z.string().describe(\"The story title.\"),    forHiring: z    .boolean()    .describe(    \"True if the story is a Ask HN post with Who is hiring, Who wants to be hired, or Seeking freelancer in the title\",    ),    sentiment: z    .enum([\"positive\", \"neutral\", \"negative\"])    .describe(\"Sentiment of the post.\"),    objectID: z.string().describe(\"objectID field\"),    });        let summaries = [];    for (const hit of searchResults.hits) {    summaries.push(    new ComputeJSON({    prompt: `Summarize this comment and how it relates to the topic: ${query}    Use \"negative\" sentiment for posts about API, abstraction, documentation, tutorial, general quality, slowness, or performance issues.    COMMENT: ${JSON.stringify(hit)}`,    json_schema: zodToJsonSchema(commentInfo),    }),    );    }            ``\n\nFinally, we use ComputeText to generate a markdown summary of all the extracted JSON, and stream the results of the `markdown` node.\n\nTypeScript\n\nPython\n\n``   const markdown = new ComputeText({    prompt: sb.concat(    `Below is a list of summarized comments about ${query} on Hacker News.    Generate concise markdown summarizing the results.    Summarize the contents of the comment and the sentiment about ${query}.    Categorize results under sentiment headers.    Order from most negative to least negative within each category.    Add a link to the original story URL in this format: [<story title>](https://news.ycombinator.com/item?id=<objectID>)    Filter out posts that do not seem to be about ${query}.    RESULTS:\\n`,    ...summaries.map((s) => sb.jq(s.future.json_object, \"@json\")),    ),    model: \"Llama3Instruct70B\",    });    const stream = await substrate.stream(markdown);            ``\n\nThe code we wrote was really simple. Implicitly, we were creating the graph below. But we didn't have to think about the graph at all! With Substrate, by simply relating tasks to each other, we get automatic parallelization of dozens of LLM calls for free, and 0 roundtrips.\n\n`comment`\n\nComputeJSON\n\n`comment`\n\nComputeJSON\n\n`comment`\n\nComputeJSON\n\nComputeText\n\n`markdown`\n\nPress enter or space to select a node.You can then use the arrow keys to move the node around. Press delete to remove it and escape to cancel.\n\nPress enter or space to select an edge. You can then press delete to remove it or escape to cancel.\n\n[Changelog](/changelog \"Changelog\")\n[Reimagine a room](/guides/reimagine-a-room \"Reimagine a room\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "markdown": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\nCTRL K\n\nCTRL K\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nExtract and summarize Hacker News comments\n\n֍\n\nLearn how to extract information (including sentiment analysis) and generate a summary (RAG)\n\nIn this guide, we'll show you how to search Hacker News comments for a topic, extract sentiment, and generate a research summary using Substrate.\n\nThis concise RAG implementation runs dozens of LLM calls in parallel and streams the markdown result. It's easy to remix the runnable TypeScript code below, [hosted on val.town (opens in a new tab)](https://www.val.town/v/substrate/hackerNewsRAG)\n.\n\n  \n\nFirst, we search HackerNews comments using the [Algolia HN Search API (opens in a new tab)](https://hn.algolia.com/api)\n.\n\nTypeScript\n\n``   const searchResults = await hnSearch({    query: query,    numericFilters: `created_at_i>${Math.floor(Date.now() / 1000) - 60 * 60 * 24 * 7 * 4}`,    tags: \"comment\",    });            ``\n\nNext, we use ComputeJSON to extract summary, sentiment, and other metadata from each comment. In TypeScript, we use [zod (opens in a new tab)](https://zod.dev/)\n and [zod-to-json-schema (opens in a new tab)](https://www.npmjs.com/package/zod-to-json-schema)\n to create the JSON schema. In Python, we use [Pydantic (opens in a new tab)](https://docs.pydantic.dev/latest/)\n.\n\nTypeScript\n\nPython\n\n``   const commentInfo = z.object({    summary: z    .string()    .describe(    \"Summarize in a couple sentences: who is commenting, what the comment is about, how it is related to the topic.\",    ),    storyTitle: z.string().describe(\"The story title.\"),    forHiring: z    .boolean()    .describe(    \"True if the story is a Ask HN post with Who is hiring, Who wants to be hired, or Seeking freelancer in the title\",    ),    sentiment: z    .enum([\"positive\", \"neutral\", \"negative\"])    .describe(\"Sentiment of the post.\"),    objectID: z.string().describe(\"objectID field\"),    });        let summaries = [];    for (const hit of searchResults.hits) {    summaries.push(    new ComputeJSON({    prompt: `Summarize this comment and how it relates to the topic: ${query}    Use \"negative\" sentiment for posts about API, abstraction, documentation, tutorial, general quality, slowness, or performance issues.    COMMENT: ${JSON.stringify(hit)}`,    json_schema: zodToJsonSchema(commentInfo),    }),    );    }            ``\n\nFinally, we use ComputeText to generate a markdown summary of all the extracted JSON, and stream the results of the `markdown` node.\n\nTypeScript\n\nPython\n\n``   const markdown = new ComputeText({    prompt: sb.concat(    `Below is a list of summarized comments about ${query} on Hacker News.    Generate concise markdown summarizing the results.    Summarize the contents of the comment and the sentiment about ${query}.    Categorize results under sentiment headers.    Order from most negative to least negative within each category.    Add a link to the original story URL in this format: [<story title>](https://news.ycombinator.com/item?id=<objectID>)    Filter out posts that do not seem to be about ${query}.    RESULTS:\\n`,    ...summaries.map((s) => sb.jq(s.future.json_object, \"@json\")),    ),    model: \"Llama3Instruct70B\",    });    const stream = await substrate.stream(markdown);            ``\n\nThe code we wrote was really simple. Implicitly, we were creating the graph below. But we didn't have to think about the graph at all! With Substrate, by simply relating tasks to each other, we get automatic parallelization of dozens of LLM calls for free, and 0 roundtrips.\n\n`comment`\n\nComputeJSON\n\n`comment`\n\nComputeJSON\n\n`comment`\n\nComputeJSON\n\nComputeText\n\n`markdown`\n\nPress enter or space to select a node.You can then use the arrow keys to move the node around. Press delete to remove it and escape to cancel.\n\nPress enter or space to select an edge. You can then press delete to remove it or escape to cancel.\n\n[Changelog](/changelog \"Changelog\")\n[Reimagine a room](/guides/reimagine-a-room \"Reimagine a room\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "metadata": {
      "ogUrl": "https://docs.substrate.run",
      "title": "Extract and Summarize | Substrate",
      "robots": "index,follow",
      "ogImage": "/og-image-v3.png",
      "ogTitle": "Extract and Summarize | Substrate",
      "sourceURL": "https://docs.substrate.run/guides/extract-and-summarize",
      "description": "Substrate",
      "ogDescription": "The platform for compound AI. Powerful SDKs, with batteries included: optimized AI models, vector storage, code interpreter, and agentic control flow. Stop using LangChain.",
      "pageStatusCode": 200,
      "ogLocaleAlternate": []
    },
    "linksOnPage": [
      "https://substrate.run",
      "https://docs.substrate.run/",
      "https://substrate.run/nodes",
      "https://substrate.run/pricing",
      "https://substrate.run/company",
      "https://blog.substrate.run",
      "https://docs.substrate.run/overview/setup",
      "https://docs.substrate.run/overview/connecting",
      "https://docs.substrate.run/overview/storing",
      "https://docs.substrate.run/why",
      "https://docs.substrate.run/changelog",
      "https://docs.substrate.run/guides/extract-and-summarize",
      "https://docs.substrate.run/guides/reimagine-a-room",
      "https://docs.substrate.run/guides/transcription",
      "https://docs.substrate.run/guides/vector-stores",
      "https://docs.substrate.run/guides/remove-background",
      "https://docs.substrate.run/guides/masked-image-generation",
      "https://docs.substrate.run/guides/mixture-of-agents",
      "https://docs.substrate.run/reference/api",
      "https://docs.substrate.run/reference/quick",
      "https://docs.substrate.run/reference/box",
      "https://docs.substrate.run/reference/if",
      "https://docs.substrate.run/reference/run-python",
      "https://docs.substrate.run/reference/streaming",
      "https://docs.substrate.run/reference/external-files",
      "https://docs.substrate.run/reference/external-files/s3",
      "https://docs.substrate.run/reference/versioning",
      "https://docs.substrate.run/reference/legal/terms-of-service",
      "https://docs.substrate.run/reference/legal/privacy-policy",
      "https://docs.substrate.run/reference/legal/usage-policy",
      "https://www.val.town/v/substrate/hackerNewsRAG",
      "https://hn.algolia.com/api",
      "https://zod.dev/",
      "https://www.npmjs.com/package/zod-to-json-schema",
      "https://docs.pydantic.dev/latest/",
      "https://x.com/substratelabs",
      "https://www.linkedin.com/company/substratelabs",
      "https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA"
    ]
  },
  {
    "content": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nReimagine a room\n\n֍\n\nGenerate variations of a room in different styles and summarize the interior design\n\nIn this example, we'll:\n\n*   Use StableDiffusionXLInpaint\n    \n    Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n    . Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n    \n    StableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    to generate variations of a photo of a room in different styles.\n*   Use StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `edge` method to generate variations structured by the edges of the original image.\n*   Use StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `depth` method to generate variations structured by a depth map of the original image.\n*   Use ComputeText\n    \n    Compute text using a language model.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#ComputeText)\n    \n    ComputeText( prompt=\"Who is Don Quixote?\", temperature=0.4, max\\_tokens=800, )\n    \n    Output\n    \n    { \"text\": \"Don Quixote is a fictional character in the novel of the same name by Miguel de Cervantes.\" }\n    \n    to summarize the final images.\n\nFirst, initialize Substrate:\n\nPython\n\nTypeScript\n\n`   from substrate import (    Substrate,    StableDiffusionXLControlNet,    StableDiffusionXLInpaint,    ComputeText,    ComputeText,    sb,    )        s = Substrate(api_key=YOUR_API_KEY)            `\n\nHere's the original image:\n\n![original](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Foffice.jpg&w=1200&q=75)\n\nWe'll first generate variations of the room using\n\nStableDiffusionXLInpaint\n\nEdit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n. Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n\nStableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\n.\n\n*   This node can also be used to inpaint the masked part of an image if a `mask_image_uri` is provided. Here we'll inpaint in the entire image.\n*   The `strength` parameter controls the strength of the generation process over the original image – higher numbers result in images further from the original.\n\nPython\n\nTypeScript\n\n`   styles = [\"sunlit onsen style tokyo office\", \"80s disco style berlin office at night\"]    images = [    StableDiffusionXLInpaint(    image_uri=\"https://media.substrate.run/office.jpg\",    strength=0.75,    prompt=s,    num_images=1,    )    for s in styles    ]    res = s.run(*images)            `\n\n![inpaint tokyo](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Finpaint-tokyo.jpg&w=1200&q=75)\n\nsunlit onsen style tokyo office\n\n![inpaint berlin](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Finpaint-berlin.jpg&w=1200&q=75)\n\n80s disco style berlin office at night\n\nWhen using this `strength` value, some of the quality of the original is preserved in the variations, but they're quite different.\n\n֍\n\nInpaintImage\n\nEdit an image using image generation inside part of the image or the full image.\n\nExample\n\n[API Reference](https://substrate.run/nodes#InpaintImage)\n\nInpaintImage( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright anime birds in a dark jungle full of vines, high resolution\", store=\"hosted\", )\n\nOutput\n\n{ \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n\nis a high-level alternative to `StableDiffusionXLControlNet`. You should use high-level nodes if you want your node to automatically update to the latest, best model.\n\nNext, we'll generate variations using\n\nStableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nwith the `edge` method, which processes the original image with an edge detection algorithm and uses edges to structure generation.\n\nPython\n\nTypeScript\n\n`   styles = [\"sunlit onsen style tokyo office\", \"80s disco style berlin office at night\"]    images = [    StableDiffusionXLControlNet(    image_uri=\"https://media.substrate.run/office.jpg\",    control_method=\"edge\",    prompt=s,    num_images=1,    )    for s in styles    ]    res = s.run(*images)            `\n\n![edge tokyo](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fedge-tokyo.jpg&w=1200&q=75)\n\nsunlit onsen style tokyo office\n\n![edge berlin](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fedge-berlin.jpg&w=1200&q=75)\n\n80s disco style berlin office at night\n\nFinally, we'll use\n\nStableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nwith the `depth` method, which processes the original image with a depth detection algorithm and uses depth to structure generation. We'll continue our workflow to describe the generated variations using ComputeText\n\nCompute text using a language model.\n\nExample\n\n[API Reference](https://substrate.run/nodes#ComputeText)\n\nComputeText( prompt=\"Who is Don Quixote?\", temperature=0.4, max\\_tokens=800, )\n\nOutput\n\n{ \"text\": \"Don Quixote is a fictional character in the novel of the same name by Miguel de Cervantes.\" }\n\n, and then summarize the generated descriptions using ComputeText\n\nCompute text using a language model.\n\nExample\n\n[API Reference](https://substrate.run/nodes#ComputeText)\n\nComputeText( prompt=\"Who is Don Quixote?\", temperature=0.4, max\\_tokens=800, )\n\nOutput\n\n{ \"text\": \"Don Quixote is a fictional character in the novel of the same name by Miguel de Cervantes.\" }\n\n.\n\nPython\n\nTypeScript\n\n`   styles = [\"sunlit onsen style tokyo office\", \"80s disco style berlin office at night\"]    images = [    StableDiffusionXLControlNet(    image_uri=\"https://media.substrate.run/office.jpg\",    control_method=\"depth\",    prompt=s,    num_images=1,    )    for s in styles    ]    descriptions = [    ComputeText(    prompt=\"Describe the interesting interior decor touches in this image\",    image_uris=[i.future.outputs[0].image_uri],    )    for i in images    ]    summaries = [    ComputeText(    prompt=sb.concat(    \"Summarize the 2 most interesting details in one sentence, be concise: \",    d.future.text,    ),    )    for d in descriptions    ]    res = s.run(*summaries)            `\n\n![edge tokyo](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fdepth-tokyo.jpg&w=1200&q=75)\n\nThe living room boasts a spacious design with a large window allowing natural light and a cozy couch. Unique is the open-concept office area, separated by a partial wall, offering a functional workspace while maintaining unity, enhanced by plants, lamps, and a rug in the modern, minimalist decor.\n\n![edge berlin](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fdepth-berlin.jpg&w=1200&q=75)\n\nThe image features a contemporary office with a captivating pink and purple color scheme: vibrant pink walls instill energy, while elegant purple furniture adds sophistication.\n\n[Extract and summarize Hacker News comments](/guides/extract-and-summarize \"Extract and summarize Hacker News comments\")\n[Transcribe audio & video](/guides/transcription \"Transcribe audio & video\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "markdown": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nReimagine a room\n\n֍\n\nGenerate variations of a room in different styles and summarize the interior design\n\nIn this example, we'll:\n\n*   Use StableDiffusionXLInpaint\n    \n    Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n    . Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n    \n    StableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    to generate variations of a photo of a room in different styles.\n*   Use StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `edge` method to generate variations structured by the edges of the original image.\n*   Use StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `depth` method to generate variations structured by a depth map of the original image.\n*   Use ComputeText\n    \n    Compute text using a language model.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#ComputeText)\n    \n    ComputeText( prompt=\"Who is Don Quixote?\", temperature=0.4, max\\_tokens=800, )\n    \n    Output\n    \n    { \"text\": \"Don Quixote is a fictional character in the novel of the same name by Miguel de Cervantes.\" }\n    \n    to summarize the final images.\n\nFirst, initialize Substrate:\n\nPython\n\nTypeScript\n\n`   from substrate import (    Substrate,    StableDiffusionXLControlNet,    StableDiffusionXLInpaint,    ComputeText,    ComputeText,    sb,    )        s = Substrate(api_key=YOUR_API_KEY)            `\n\nHere's the original image:\n\n![original](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Foffice.jpg&w=1200&q=75)\n\nWe'll first generate variations of the room using\n\nStableDiffusionXLInpaint\n\nEdit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n. Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n\nStableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\n.\n\n*   This node can also be used to inpaint the masked part of an image if a `mask_image_uri` is provided. Here we'll inpaint in the entire image.\n*   The `strength` parameter controls the strength of the generation process over the original image – higher numbers result in images further from the original.\n\nPython\n\nTypeScript\n\n`   styles = [\"sunlit onsen style tokyo office\", \"80s disco style berlin office at night\"]    images = [    StableDiffusionXLInpaint(    image_uri=\"https://media.substrate.run/office.jpg\",    strength=0.75,    prompt=s,    num_images=1,    )    for s in styles    ]    res = s.run(*images)            `\n\n![inpaint tokyo](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Finpaint-tokyo.jpg&w=1200&q=75)\n\nsunlit onsen style tokyo office\n\n![inpaint berlin](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Finpaint-berlin.jpg&w=1200&q=75)\n\n80s disco style berlin office at night\n\nWhen using this `strength` value, some of the quality of the original is preserved in the variations, but they're quite different.\n\n֍\n\nInpaintImage\n\nEdit an image using image generation inside part of the image or the full image.\n\nExample\n\n[API Reference](https://substrate.run/nodes#InpaintImage)\n\nInpaintImage( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright anime birds in a dark jungle full of vines, high resolution\", store=\"hosted\", )\n\nOutput\n\n{ \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n\nis a high-level alternative to `StableDiffusionXLControlNet`. You should use high-level nodes if you want your node to automatically update to the latest, best model.\n\nNext, we'll generate variations using\n\nStableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nwith the `edge` method, which processes the original image with an edge detection algorithm and uses edges to structure generation.\n\nPython\n\nTypeScript\n\n`   styles = [\"sunlit onsen style tokyo office\", \"80s disco style berlin office at night\"]    images = [    StableDiffusionXLControlNet(    image_uri=\"https://media.substrate.run/office.jpg\",    control_method=\"edge\",    prompt=s,    num_images=1,    )    for s in styles    ]    res = s.run(*images)            `\n\n![edge tokyo](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fedge-tokyo.jpg&w=1200&q=75)\n\nsunlit onsen style tokyo office\n\n![edge berlin](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fedge-berlin.jpg&w=1200&q=75)\n\n80s disco style berlin office at night\n\nFinally, we'll use\n\nStableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nwith the `depth` method, which processes the original image with a depth detection algorithm and uses depth to structure generation. We'll continue our workflow to describe the generated variations using ComputeText\n\nCompute text using a language model.\n\nExample\n\n[API Reference](https://substrate.run/nodes#ComputeText)\n\nComputeText( prompt=\"Who is Don Quixote?\", temperature=0.4, max\\_tokens=800, )\n\nOutput\n\n{ \"text\": \"Don Quixote is a fictional character in the novel of the same name by Miguel de Cervantes.\" }\n\n, and then summarize the generated descriptions using ComputeText\n\nCompute text using a language model.\n\nExample\n\n[API Reference](https://substrate.run/nodes#ComputeText)\n\nComputeText( prompt=\"Who is Don Quixote?\", temperature=0.4, max\\_tokens=800, )\n\nOutput\n\n{ \"text\": \"Don Quixote is a fictional character in the novel of the same name by Miguel de Cervantes.\" }\n\n.\n\nPython\n\nTypeScript\n\n`   styles = [\"sunlit onsen style tokyo office\", \"80s disco style berlin office at night\"]    images = [    StableDiffusionXLControlNet(    image_uri=\"https://media.substrate.run/office.jpg\",    control_method=\"depth\",    prompt=s,    num_images=1,    )    for s in styles    ]    descriptions = [    ComputeText(    prompt=\"Describe the interesting interior decor touches in this image\",    image_uris=[i.future.outputs[0].image_uri],    )    for i in images    ]    summaries = [    ComputeText(    prompt=sb.concat(    \"Summarize the 2 most interesting details in one sentence, be concise: \",    d.future.text,    ),    )    for d in descriptions    ]    res = s.run(*summaries)            `\n\n![edge tokyo](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fdepth-tokyo.jpg&w=1200&q=75)\n\nThe living room boasts a spacious design with a large window allowing natural light and a cozy couch. Unique is the open-concept office area, separated by a partial wall, offering a functional workspace while maintaining unity, enhanced by plants, lamps, and a rug in the modern, minimalist decor.\n\n![edge berlin](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fdepth-berlin.jpg&w=1200&q=75)\n\nThe image features a contemporary office with a captivating pink and purple color scheme: vibrant pink walls instill energy, while elegant purple furniture adds sophistication.\n\n[Extract and summarize Hacker News comments](/guides/extract-and-summarize \"Extract and summarize Hacker News comments\")\n[Transcribe audio & video](/guides/transcription \"Transcribe audio & video\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "metadata": {
      "ogUrl": "https://docs.substrate.run",
      "title": "Reimagine a Room | Substrate",
      "robots": "index,follow",
      "ogImage": "/og-image-v3.png",
      "ogTitle": "Reimagine a Room | Substrate",
      "sourceURL": "https://docs.substrate.run/guides/reimagine-a-room",
      "description": "Substrate",
      "ogDescription": "The platform for compound AI. Powerful SDKs, with batteries included: optimized AI models, vector storage, code interpreter, and agentic control flow. Stop using LangChain.",
      "pageStatusCode": 200,
      "ogLocaleAlternate": []
    },
    "linksOnPage": [
      "https://substrate.run",
      "https://docs.substrate.run/",
      "https://substrate.run/nodes",
      "https://substrate.run/pricing",
      "https://substrate.run/company",
      "https://blog.substrate.run",
      "https://docs.substrate.run/overview/setup",
      "https://docs.substrate.run/overview/connecting",
      "https://docs.substrate.run/overview/storing",
      "https://docs.substrate.run/why",
      "https://docs.substrate.run/changelog",
      "https://docs.substrate.run/guides/extract-and-summarize",
      "https://docs.substrate.run/guides/reimagine-a-room",
      "https://docs.substrate.run/guides/transcription",
      "https://docs.substrate.run/guides/vector-stores",
      "https://docs.substrate.run/guides/remove-background",
      "https://docs.substrate.run/guides/masked-image-generation",
      "https://docs.substrate.run/guides/mixture-of-agents",
      "https://docs.substrate.run/reference/api",
      "https://docs.substrate.run/reference/quick",
      "https://docs.substrate.run/reference/box",
      "https://docs.substrate.run/reference/if",
      "https://docs.substrate.run/reference/run-python",
      "https://docs.substrate.run/reference/streaming",
      "https://docs.substrate.run/reference/external-files",
      "https://docs.substrate.run/reference/external-files/s3",
      "https://docs.substrate.run/reference/versioning",
      "https://docs.substrate.run/reference/legal/terms-of-service",
      "https://docs.substrate.run/reference/legal/privacy-policy",
      "https://docs.substrate.run/reference/legal/usage-policy",
      "https://arxiv.org/abs/2307.01952",
      "https://substrate.run/nodes#StableDiffusionXLInpaint",
      "https://arxiv.org/abs/2302.05543",
      "https://substrate.run/nodes#StableDiffusionXLControlNet",
      "https://substrate.run/nodes#ComputeText",
      "https://substrate.run/nodes#InpaintImage",
      "https://x.com/substratelabs",
      "https://www.linkedin.com/company/substratelabs",
      "https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA"
    ]
  },
  {
    "content": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nTranscribe audio & video\n\n֍\n\nLearn how to transcribe audio and video\n\nThe\n\nTranscribeSpeech\n\nTranscribe speech in an audio or video file.\n\nExample\n\n[API Reference](https://substrate.run/nodes#TranscribeSpeech)\n\nTranscribeSpeech( audio\\_uri=\"https://media.substrate.run/dfw-clip.m4a\", prompt=\"David Foster Wallace interviewed about US culture, and Infinite Jest\", segment=True, align=True, diarize=True, suggest\\_chapters=True, )\n\nOutput\n\n{ \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that ...\", \"segments\": \\[ { \"start\": 0.874, \"end\": 15.353, \"speaker\": \"SPEAKER\\_00\", \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that\", \"words\": \\[ { \"word\": \"language\", \"start\": 0.874, \"end\": 1.275, \"speaker\": \"SPEAKER\\_00\" }, { \"word\": \"like\", \"start\": 1.295, \"end\": 1.455, \"speaker\": \"SPEAKER\\_00\" } \\] } \\], \"chapters\": \\[ { \"title\": \"Introduction to the Wounded Inner Child and Popular Psychology in US\", \"start\": 0.794 }, { \"title\": \"The Paradox of Popular Psychology and Anger in America\", \"start\": 16.186 } \\] }\n\nnode transcribes speech from audio or video input, with additional built-in capabilities:\n\n*   segmentation by sentence\n*   diarization (speaker identification)\n*   alignment to word-level timestamps\n*   automatic chapter detection\n\nTo simply transcribe input without further processing, provide an `audio_uri`. This can be a publicly-hosted audio or video file, base-64-encoded audio or video data, or a privately-hosted [external file (opens in a new tab)](http://localhost:3000/reference/external-files)\n. For best results, you may also provide a `prompt` that describes the content of the audio or video.\n\nPython\n\nTypeScript\n\n`   from substrate import Substrate, TranscribeSpeech        # ...        transcript = TranscribeSpeech(    audio_uri=\"https://media.substrate.run/dfw-clip.m4a\",    prompt=\"David Foster Wallace interviewed about US culture\",    )    res = substrate.run(transcript)            `\n\nOutput\n\n`   {    \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that ...\"    }            `\n\nTo enable additional capabilities, set:\n\n*   `segment: True` to return a list of sentence `segments` with `start` and `end` timestamps.\n*   `align: True` to return a list of aligned `words` within sentence `segments`.\n*   `diarize: True` to include `speaker` IDs within `segments` and `words`.\n*   `suggest_chapters: True` to return a list of suggested `chapters` with titles and `start` timestamps.\n\nPython\n\nTypeScript\n\n`   transcript = TranscribeSpeech(    audio_uri=\"https://media.substrate.run/dfw-clip.m4a\",    prompt=\"David Foster Wallace interviewed about US culture\",    segment=True,    align=True,    diarize=True,    suggest_chapters=True,    )            `\n\nOutput\n\n`   {    \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that ...\",    \"segments\": [    {    \"start\": 0.874,    \"end\": 15.353,    \"speaker\": \"SPEAKER_00\",    \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that\",    \"words\": [    {    \"word\": \"language\",    \"start\": 0.874,    \"end\": 1.275,    \"speaker\": \"SPEAKER_00\"    },    {    \"word\": \"like\",    \"start\": 1.295,    \"end\": 1.455,    \"speaker\": \"SPEAKER_00\"    }    ]    }    ],    \"chapters\": [    {    \"title\": \"Introduction to the Wounded Inner Child and Popular Psychology in US\",    \"start\": 0.794    },    {    \"title\": \"The Paradox of Popular Psychology and Anger in America\",    \"start\": 16.186    }    ]    }            `\n\n[Reimagine a room](/guides/reimagine-a-room \"Reimagine a room\")\n[Store & query vectors](/guides/vector-stores \"Store & query vectors\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "markdown": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nTranscribe audio & video\n\n֍\n\nLearn how to transcribe audio and video\n\nThe\n\nTranscribeSpeech\n\nTranscribe speech in an audio or video file.\n\nExample\n\n[API Reference](https://substrate.run/nodes#TranscribeSpeech)\n\nTranscribeSpeech( audio\\_uri=\"https://media.substrate.run/dfw-clip.m4a\", prompt=\"David Foster Wallace interviewed about US culture, and Infinite Jest\", segment=True, align=True, diarize=True, suggest\\_chapters=True, )\n\nOutput\n\n{ \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that ...\", \"segments\": \\[ { \"start\": 0.874, \"end\": 15.353, \"speaker\": \"SPEAKER\\_00\", \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that\", \"words\": \\[ { \"word\": \"language\", \"start\": 0.874, \"end\": 1.275, \"speaker\": \"SPEAKER\\_00\" }, { \"word\": \"like\", \"start\": 1.295, \"end\": 1.455, \"speaker\": \"SPEAKER\\_00\" } \\] } \\], \"chapters\": \\[ { \"title\": \"Introduction to the Wounded Inner Child and Popular Psychology in US\", \"start\": 0.794 }, { \"title\": \"The Paradox of Popular Psychology and Anger in America\", \"start\": 16.186 } \\] }\n\nnode transcribes speech from audio or video input, with additional built-in capabilities:\n\n*   segmentation by sentence\n*   diarization (speaker identification)\n*   alignment to word-level timestamps\n*   automatic chapter detection\n\nTo simply transcribe input without further processing, provide an `audio_uri`. This can be a publicly-hosted audio or video file, base-64-encoded audio or video data, or a privately-hosted [external file (opens in a new tab)](http://localhost:3000/reference/external-files)\n. For best results, you may also provide a `prompt` that describes the content of the audio or video.\n\nPython\n\nTypeScript\n\n`   from substrate import Substrate, TranscribeSpeech        # ...        transcript = TranscribeSpeech(    audio_uri=\"https://media.substrate.run/dfw-clip.m4a\",    prompt=\"David Foster Wallace interviewed about US culture\",    )    res = substrate.run(transcript)            `\n\nOutput\n\n`   {    \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that ...\"    }            `\n\nTo enable additional capabilities, set:\n\n*   `segment: True` to return a list of sentence `segments` with `start` and `end` timestamps.\n*   `align: True` to return a list of aligned `words` within sentence `segments`.\n*   `diarize: True` to include `speaker` IDs within `segments` and `words`.\n*   `suggest_chapters: True` to return a list of suggested `chapters` with titles and `start` timestamps.\n\nPython\n\nTypeScript\n\n`   transcript = TranscribeSpeech(    audio_uri=\"https://media.substrate.run/dfw-clip.m4a\",    prompt=\"David Foster Wallace interviewed about US culture\",    segment=True,    align=True,    diarize=True,    suggest_chapters=True,    )            `\n\nOutput\n\n`   {    \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that ...\",    \"segments\": [    {    \"start\": 0.874,    \"end\": 15.353,    \"speaker\": \"SPEAKER_00\",    \"text\": \"language like that, the wounded inner child, the inner pain, is part of a kind of pop psychological movement in the United States that is a sort of popular Freudianism that\",    \"words\": [    {    \"word\": \"language\",    \"start\": 0.874,    \"end\": 1.275,    \"speaker\": \"SPEAKER_00\"    },    {    \"word\": \"like\",    \"start\": 1.295,    \"end\": 1.455,    \"speaker\": \"SPEAKER_00\"    }    ]    }    ],    \"chapters\": [    {    \"title\": \"Introduction to the Wounded Inner Child and Popular Psychology in US\",    \"start\": 0.794    },    {    \"title\": \"The Paradox of Popular Psychology and Anger in America\",    \"start\": 16.186    }    ]    }            `\n\n[Reimagine a room](/guides/reimagine-a-room \"Reimagine a room\")\n[Store & query vectors](/guides/vector-stores \"Store & query vectors\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "metadata": {
      "ogUrl": "https://docs.substrate.run",
      "title": "Transcription | Substrate",
      "robots": "index,follow",
      "ogImage": "/og-image-v3.png",
      "ogTitle": "Transcription | Substrate",
      "sourceURL": "https://docs.substrate.run/guides/transcription",
      "description": "Substrate",
      "ogDescription": "The platform for compound AI. Powerful SDKs, with batteries included: optimized AI models, vector storage, code interpreter, and agentic control flow. Stop using LangChain.",
      "pageStatusCode": 200,
      "ogLocaleAlternate": []
    },
    "linksOnPage": [
      "https://substrate.run",
      "https://docs.substrate.run/",
      "https://substrate.run/nodes",
      "https://substrate.run/pricing",
      "https://substrate.run/company",
      "https://blog.substrate.run",
      "https://docs.substrate.run/overview/setup",
      "https://docs.substrate.run/overview/connecting",
      "https://docs.substrate.run/overview/storing",
      "https://docs.substrate.run/why",
      "https://docs.substrate.run/changelog",
      "https://docs.substrate.run/guides/extract-and-summarize",
      "https://docs.substrate.run/guides/reimagine-a-room",
      "https://docs.substrate.run/guides/transcription",
      "https://docs.substrate.run/guides/vector-stores",
      "https://docs.substrate.run/guides/remove-background",
      "https://docs.substrate.run/guides/masked-image-generation",
      "https://docs.substrate.run/guides/mixture-of-agents",
      "https://docs.substrate.run/reference/api",
      "https://docs.substrate.run/reference/quick",
      "https://docs.substrate.run/reference/box",
      "https://docs.substrate.run/reference/if",
      "https://docs.substrate.run/reference/run-python",
      "https://docs.substrate.run/reference/streaming",
      "https://docs.substrate.run/reference/external-files",
      "https://docs.substrate.run/reference/external-files/s3",
      "https://docs.substrate.run/reference/versioning",
      "https://docs.substrate.run/reference/legal/terms-of-service",
      "https://docs.substrate.run/reference/legal/privacy-policy",
      "https://docs.substrate.run/reference/legal/usage-policy",
      "https://substrate.run/nodes#TranscribeSpeech",
      "http://localhost:3000/reference/external-files",
      "https://x.com/substratelabs",
      "https://www.linkedin.com/company/substratelabs",
      "https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA"
    ]
  },
  {
    "content": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nStore & query vectors\n\n֍\n\nLearn how to store vectors and query a vector store\n\nSubstrate comes with built-in vector storage, which you can use to store and query generated embeddings. In this example, we'll embed a set of common phrases used to enhance image generation prompts. Then, we'll query the vector store with a given prompt to recommend phrases to enhance the prompt.\n\nFirst, we'll create a new vector store using\n\nFindOrCreateVectorStore\n\nFind a vector store matching the given collection name, or create a new vector store.\n\nExample\n\n[API Reference](https://substrate.run/nodes#FindOrCreateVectorStore)\n\nFindOrCreateVectorStore( collection\\_name=\"smoke\\_tests\", model=\"jina-v2\", )\n\nOutput\n\n{ \"collection\\_name\": \"smoke\\_tests\", \"model\": \"jina-v2\" }\n\n, providing a name for the collection, and the model we'll use to embed our data.\n\nPython\n\nTypeScript\n\n`   create = FindOrCreateVectorStore(    collection_name=\"image_prompt_enhancements\",    model=\"jina-v2\",    );    create_res = substrate.run(create)            `\n\nNext, we'll embed the enhancement phrases using\n\nEmbedText\n\nGenerate embedding for a text document.\n\nExample\n\n[API Reference](https://substrate.run/nodes#EmbedText)\n\nEmbedText( text=\"Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\", model=\"jina-v2\", collection\\_name=\"smoke\\_tests\", metadata={ \"group\": \"18\", }, embedded\\_metadata\\_keys=\\[ \"group\", \\], )\n\nOutput\n\n{ \"embedding\": { \"vector\": \\[ -0.035030052065849304, -0.04128379374742508, 0.05782046541571617 \\], \"doc\\_id\": \"c9de81fb98804ce0afb2b8ac17c0799b\", \"metadata\": { \"group\": \"18\", \"doc\\_id\": \"c9de81fb98804ce0afb2b8ac17c0799b\", \"doc\": \"group: 18 Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\" } } }\n\nproviding the text to embed, the name of the collection, and the embedding model. We'll create an array of embedding nodes, and Substrate will automatically run the nodes in parallel.\n\nPython\n\nTypeScript\n\n`   enhancements = [    \"highly detailed\",    \"cell shaded cartoon\",    \"concept art\",    \"octane render\",    \"volumetric lighting\",    \"8k postprocessing\",    \"cinematic\",    \"sharp focus\",    ]    nodes = []    for e in enhancements:    embed = EmbedText(    text=e,    collection_name=\"image_prompt_enhancements\",    model=\"jina-v2\",    )    nodes.append(embed)    embed_res = substrate.run(*nodes)            `\n\nFinally, we'll query the vector store with a given prompt using\n\nQueryVectorStore\n\nQuery a vector store for similar vectors.\n\nExample\n\n[API Reference](https://substrate.run/nodes#QueryVectorStore)\n\nQueryVectorStore( collection\\_name=\"smoke\\_tests\", model=\"jina-v2\", query\\_strings=\\[ \"gas\", \"metal\", \\], top\\_k=1, include\\_metadata=True, )\n\nOutput\n\n{ \"results\": \\[ \\[ { \"id\": \"483e75021c9d4ad69c3d78ace76da2ea\", \"distance\": -0.78324556350708, \"metadata\": { \"doc\": \"group: 18 Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\", \"group\": \"18\", \"doc\\_id\": \"483e75021c9d4ad69c3d78ace76da2ea\" } } \\], \\[ { \"id\": \"dd8f3774e05d42caa53cfbaa7389c08f\", \"distance\": -0.74278724193573, \"metadata\": { \"doc\": \"group: 8 Osmium is the densest naturally occurring element. When experimentally measured using X-ray crystallography, it has a density of 22.59 g/cm3. Manufacturers use its alloys with platinum, iridium, and other platinum-group metals to make fountain pen nib tipping, electrical contacts, and in other applications that require extreme durability and hardness.\", \"group\": \"8\", \"doc\\_id\": \"dd8f3774e05d42caa53cfbaa7389c08f\" } } \\] \\], \"collection\\_name\": \"comments\", \"model\": \"jina-v2\" }\n\n, providing the query string, the collection name, and the embedding model.\n\n*   We'll set `include_metadata` to `True` to include metadata in the response, as the metadata includes the embedded text in the `doc` field.\n*   We'll set `top_k` to 3 to retrieve only the top 3 most similar results.\n\nPython\n\nTypeScript\n\n`   query = QueryVectorStore(    query_strings=[\"a towering shell the size of a city skyscraper\"],    collection_name=\"image_prompt_enhancements\",    model=\"jina-v2\",    include_metadata=True,    top_k=3,    )    query_res = substrate.run(query)    query_out = query_res.get(query)            `\n\nThe output of\n\nQueryVectorStore\n\nQuery a vector store for similar vectors.\n\nExample\n\n[API Reference](https://substrate.run/nodes#QueryVectorStore)\n\nQueryVectorStore( collection\\_name=\"smoke\\_tests\", model=\"jina-v2\", query\\_strings=\\[ \"gas\", \"metal\", \\], top\\_k=1, include\\_metadata=True, )\n\nOutput\n\n{ \"results\": \\[ \\[ { \"id\": \"483e75021c9d4ad69c3d78ace76da2ea\", \"distance\": -0.78324556350708, \"metadata\": { \"doc\": \"group: 18 Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\", \"group\": \"18\", \"doc\\_id\": \"483e75021c9d4ad69c3d78ace76da2ea\" } } \\], \\[ { \"id\": \"dd8f3774e05d42caa53cfbaa7389c08f\", \"distance\": -0.74278724193573, \"metadata\": { \"doc\": \"group: 8 Osmium is the densest naturally occurring element. When experimentally measured using X-ray crystallography, it has a density of 22.59 g/cm3. Manufacturers use its alloys with platinum, iridium, and other platinum-group metals to make fountain pen nib tipping, electrical contacts, and in other applications that require extreme durability and hardness.\", \"group\": \"8\", \"doc\\_id\": \"dd8f3774e05d42caa53cfbaa7389c08f\" } } \\] \\], \"collection\\_name\": \"comments\", \"model\": \"jina-v2\" }\n\nhas query results in the `results` field, which is a _list of lists_. In this example, it contains a single list of results. If we instead provided two `query_strings`, it would contain two lists of results, one for each query string.\n\nOutput\n\n`   {    \"results\": [    [    {    \"id\": \"079ee5765c8c4df98b50bdb7b5cbdd29\",    \"distance\": -0.723642945289612,    \"vector\": null,    \"metadata\": {    \"doc\": \"cell shaded cartoon\",    \"doc_id\": \"079ee5765c8c4df98b50bdb7b5cbdd29\"    }    },    {    \"id\": \"98ec8bb1da1243d88721645fc0a8899b\",    \"distance\": -0.717301785945892,    \"vector\": null,    \"metadata\": {    \"doc\": \"cinematic\",    \"doc_id\": \"98ec8bb1da1243d88721645fc0a8899b\"    }    },    {    \"id\": \"158f2fc695e648878d245fdf93fa2917\",    \"distance\": -0.715586066246033,    \"vector\": null,    \"metadata\": {    \"doc\": \"wide shot\",    \"doc_id\": \"158f2fc695e648878d245fdf93fa2917\"    }    }    ]    ],    \"collection_name\": null,    \"model\": \"jina-v2\",    \"metric\": \"inner\"    }            `\n\n[Transcribe audio & video](/guides/transcription \"Transcribe audio & video\")\n[Separate foreground & background](/guides/remove-background \"Separate foreground & background\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "markdown": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nStore & query vectors\n\n֍\n\nLearn how to store vectors and query a vector store\n\nSubstrate comes with built-in vector storage, which you can use to store and query generated embeddings. In this example, we'll embed a set of common phrases used to enhance image generation prompts. Then, we'll query the vector store with a given prompt to recommend phrases to enhance the prompt.\n\nFirst, we'll create a new vector store using\n\nFindOrCreateVectorStore\n\nFind a vector store matching the given collection name, or create a new vector store.\n\nExample\n\n[API Reference](https://substrate.run/nodes#FindOrCreateVectorStore)\n\nFindOrCreateVectorStore( collection\\_name=\"smoke\\_tests\", model=\"jina-v2\", )\n\nOutput\n\n{ \"collection\\_name\": \"smoke\\_tests\", \"model\": \"jina-v2\" }\n\n, providing a name for the collection, and the model we'll use to embed our data.\n\nPython\n\nTypeScript\n\n`   create = FindOrCreateVectorStore(    collection_name=\"image_prompt_enhancements\",    model=\"jina-v2\",    );    create_res = substrate.run(create)            `\n\nNext, we'll embed the enhancement phrases using\n\nEmbedText\n\nGenerate embedding for a text document.\n\nExample\n\n[API Reference](https://substrate.run/nodes#EmbedText)\n\nEmbedText( text=\"Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\", model=\"jina-v2\", collection\\_name=\"smoke\\_tests\", metadata={ \"group\": \"18\", }, embedded\\_metadata\\_keys=\\[ \"group\", \\], )\n\nOutput\n\n{ \"embedding\": { \"vector\": \\[ -0.035030052065849304, -0.04128379374742508, 0.05782046541571617 \\], \"doc\\_id\": \"c9de81fb98804ce0afb2b8ac17c0799b\", \"metadata\": { \"group\": \"18\", \"doc\\_id\": \"c9de81fb98804ce0afb2b8ac17c0799b\", \"doc\": \"group: 18 Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\" } } }\n\nproviding the text to embed, the name of the collection, and the embedding model. We'll create an array of embedding nodes, and Substrate will automatically run the nodes in parallel.\n\nPython\n\nTypeScript\n\n`   enhancements = [    \"highly detailed\",    \"cell shaded cartoon\",    \"concept art\",    \"octane render\",    \"volumetric lighting\",    \"8k postprocessing\",    \"cinematic\",    \"sharp focus\",    ]    nodes = []    for e in enhancements:    embed = EmbedText(    text=e,    collection_name=\"image_prompt_enhancements\",    model=\"jina-v2\",    )    nodes.append(embed)    embed_res = substrate.run(*nodes)            `\n\nFinally, we'll query the vector store with a given prompt using\n\nQueryVectorStore\n\nQuery a vector store for similar vectors.\n\nExample\n\n[API Reference](https://substrate.run/nodes#QueryVectorStore)\n\nQueryVectorStore( collection\\_name=\"smoke\\_tests\", model=\"jina-v2\", query\\_strings=\\[ \"gas\", \"metal\", \\], top\\_k=1, include\\_metadata=True, )\n\nOutput\n\n{ \"results\": \\[ \\[ { \"id\": \"483e75021c9d4ad69c3d78ace76da2ea\", \"distance\": -0.78324556350708, \"metadata\": { \"doc\": \"group: 18 Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\", \"group\": \"18\", \"doc\\_id\": \"483e75021c9d4ad69c3d78ace76da2ea\" } } \\], \\[ { \"id\": \"dd8f3774e05d42caa53cfbaa7389c08f\", \"distance\": -0.74278724193573, \"metadata\": { \"doc\": \"group: 8 Osmium is the densest naturally occurring element. When experimentally measured using X-ray crystallography, it has a density of 22.59 g/cm3. Manufacturers use its alloys with platinum, iridium, and other platinum-group metals to make fountain pen nib tipping, electrical contacts, and in other applications that require extreme durability and hardness.\", \"group\": \"8\", \"doc\\_id\": \"dd8f3774e05d42caa53cfbaa7389c08f\" } } \\] \\], \"collection\\_name\": \"comments\", \"model\": \"jina-v2\" }\n\n, providing the query string, the collection name, and the embedding model.\n\n*   We'll set `include_metadata` to `True` to include metadata in the response, as the metadata includes the embedded text in the `doc` field.\n*   We'll set `top_k` to 3 to retrieve only the top 3 most similar results.\n\nPython\n\nTypeScript\n\n`   query = QueryVectorStore(    query_strings=[\"a towering shell the size of a city skyscraper\"],    collection_name=\"image_prompt_enhancements\",    model=\"jina-v2\",    include_metadata=True,    top_k=3,    )    query_res = substrate.run(query)    query_out = query_res.get(query)            `\n\nThe output of\n\nQueryVectorStore\n\nQuery a vector store for similar vectors.\n\nExample\n\n[API Reference](https://substrate.run/nodes#QueryVectorStore)\n\nQueryVectorStore( collection\\_name=\"smoke\\_tests\", model=\"jina-v2\", query\\_strings=\\[ \"gas\", \"metal\", \\], top\\_k=1, include\\_metadata=True, )\n\nOutput\n\n{ \"results\": \\[ \\[ { \"id\": \"483e75021c9d4ad69c3d78ace76da2ea\", \"distance\": -0.78324556350708, \"metadata\": { \"doc\": \"group: 18 Argon is the third most abundant gas in Earth's atmosphere, at 0.934% (9340 ppmv). It is more than twice as abundant as water vapor.\", \"group\": \"18\", \"doc\\_id\": \"483e75021c9d4ad69c3d78ace76da2ea\" } } \\], \\[ { \"id\": \"dd8f3774e05d42caa53cfbaa7389c08f\", \"distance\": -0.74278724193573, \"metadata\": { \"doc\": \"group: 8 Osmium is the densest naturally occurring element. When experimentally measured using X-ray crystallography, it has a density of 22.59 g/cm3. Manufacturers use its alloys with platinum, iridium, and other platinum-group metals to make fountain pen nib tipping, electrical contacts, and in other applications that require extreme durability and hardness.\", \"group\": \"8\", \"doc\\_id\": \"dd8f3774e05d42caa53cfbaa7389c08f\" } } \\] \\], \"collection\\_name\": \"comments\", \"model\": \"jina-v2\" }\n\nhas query results in the `results` field, which is a _list of lists_. In this example, it contains a single list of results. If we instead provided two `query_strings`, it would contain two lists of results, one for each query string.\n\nOutput\n\n`   {    \"results\": [    [    {    \"id\": \"079ee5765c8c4df98b50bdb7b5cbdd29\",    \"distance\": -0.723642945289612,    \"vector\": null,    \"metadata\": {    \"doc\": \"cell shaded cartoon\",    \"doc_id\": \"079ee5765c8c4df98b50bdb7b5cbdd29\"    }    },    {    \"id\": \"98ec8bb1da1243d88721645fc0a8899b\",    \"distance\": -0.717301785945892,    \"vector\": null,    \"metadata\": {    \"doc\": \"cinematic\",    \"doc_id\": \"98ec8bb1da1243d88721645fc0a8899b\"    }    },    {    \"id\": \"158f2fc695e648878d245fdf93fa2917\",    \"distance\": -0.715586066246033,    \"vector\": null,    \"metadata\": {    \"doc\": \"wide shot\",    \"doc_id\": \"158f2fc695e648878d245fdf93fa2917\"    }    }    ]    ],    \"collection_name\": null,    \"model\": \"jina-v2\",    \"metric\": \"inner\"    }            `\n\n[Transcribe audio & video](/guides/transcription \"Transcribe audio & video\")\n[Separate foreground & background](/guides/remove-background \"Separate foreground & background\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "metadata": {
      "ogUrl": "https://docs.substrate.run",
      "title": "Vector Stores | Substrate",
      "robots": "index,follow",
      "ogImage": "/og-image-v3.png",
      "ogTitle": "Vector Stores | Substrate",
      "sourceURL": "https://docs.substrate.run/guides/vector-stores",
      "description": "Substrate",
      "ogDescription": "The platform for compound AI. Powerful SDKs, with batteries included: optimized AI models, vector storage, code interpreter, and agentic control flow. Stop using LangChain.",
      "pageStatusCode": 200,
      "ogLocaleAlternate": []
    },
    "linksOnPage": [
      "https://substrate.run",
      "https://docs.substrate.run/",
      "https://substrate.run/nodes",
      "https://substrate.run/pricing",
      "https://substrate.run/company",
      "https://blog.substrate.run",
      "https://docs.substrate.run/overview/setup",
      "https://docs.substrate.run/overview/connecting",
      "https://docs.substrate.run/overview/storing",
      "https://docs.substrate.run/why",
      "https://docs.substrate.run/changelog",
      "https://docs.substrate.run/guides/extract-and-summarize",
      "https://docs.substrate.run/guides/reimagine-a-room",
      "https://docs.substrate.run/guides/transcription",
      "https://docs.substrate.run/guides/vector-stores",
      "https://docs.substrate.run/guides/remove-background",
      "https://docs.substrate.run/guides/masked-image-generation",
      "https://docs.substrate.run/guides/mixture-of-agents",
      "https://docs.substrate.run/reference/api",
      "https://docs.substrate.run/reference/quick",
      "https://docs.substrate.run/reference/box",
      "https://docs.substrate.run/reference/if",
      "https://docs.substrate.run/reference/run-python",
      "https://docs.substrate.run/reference/streaming",
      "https://docs.substrate.run/reference/external-files",
      "https://docs.substrate.run/reference/external-files/s3",
      "https://docs.substrate.run/reference/versioning",
      "https://docs.substrate.run/reference/legal/terms-of-service",
      "https://docs.substrate.run/reference/legal/privacy-policy",
      "https://docs.substrate.run/reference/legal/usage-policy",
      "https://substrate.run/nodes#FindOrCreateVectorStore",
      "https://substrate.run/nodes#EmbedText",
      "https://substrate.run/nodes#QueryVectorStore",
      "https://x.com/substratelabs",
      "https://www.linkedin.com/company/substratelabs",
      "https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA"
    ]
  },
  {
    "content": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nSeparate foreground & background\n\n֍\n\nGenerate an image, remove the background, and fill the foreground\n\nIn this example, we'll create a branching image generation workflow that:\n\n*   Generates an image using GenerateImage\n    \n    Generate an image.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#GenerateImage)\n    \n    GenerateImage( prompt=\"hokusai futuristic supercell spiral cloud with glowing core over turbulent ocean\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n*   Removes the background from the image using RemoveBackground\n    \n    Remove the background from an image and return the foreground segment as a cut-out or a mask.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#RemoveBackground)\n    \n    RemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n*   Generates a masked foreground from the image using RemoveBackground\n    \n    Remove the background from an image and return the foreground segment as a cut-out or a mask.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#RemoveBackground)\n    \n    RemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n    , with `return_mask` enabled\n*   Fills the masked foreground using EraseImage\n    \n    Erase the masked part of an image, e.g. to remove an object by inpainting.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#EraseImage)\n    \n    EraseImage( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", mask\\_image\\_uri=\"https://media.substrate.run/apple-forest-mask.jpeg\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n\nFirst, initialize Substrate:\n\nPython\n\nTypeScript\n\n`   from substrate import (    Substrate,    GenerateImage,    RemoveBackground,    EraseImage,    sb,    )        s = Substrate(api_key=YOUR_API_KEY)            `\n\nCreate and connect four nodes and run them:\n\nPython\n\nTypeScript\n\n`   image = GenerateImage(    prompt=\"a dark red chesterfield leather wing chair in a dark majestic room, pillars, celestial galaxy wallpaper\",    )    bg = RemoveBackground(image_uri=image.future.image_uri)    mask = RemoveBackground(    image_uri=image.future.image_uri,    return_mask=True,    )    erase = EraseImage(    image_uri=image.future.image_uri,    mask_image_uri=mask.future.image_uri,    )    res = s.run(erase)            `\n\n[Run this example](https://explore.substrate.run/s/eNrNlFtv0zAUx7-KZfUxSIOu3dY3JsYugNq1Qkyg6ci1T1MTJ7ZO7HZdle8-OxQWxJAoAmlvORfbv_-5ZMsrq7Dmoy9brhUftWZ_cAJh8GKtr9DwrHXFyDlWSMLjZSlyjG5BeTy35Y5s6XxMEEwJKhihYnKJtUdaaDSKGRR-icTWuspjRGhiumK77FJ8jalaMrK2zJhEk0xhWC6MuNuwtTDGCYfEm4xDvbTBKLDBu-AhN3Yewxs-8hSwyboShgeA80_mbnwYHiVMsbQrPBWyyMmGSnVU6KQKAulkAPR6s1M4n76eXMB4Apdvej2AeMEi-EA4PO6DLQ8-3xzdLHmzJ9dL6A834zMnV_-BawDXi3B9EWarVC7C6K2gFHXxHWUv1FcQPpjJu0Vx-Ih6RqL-ZQT2gzwCdz-HcgbTBJnoYL8LTkC9nVwd3398_wfVv8125zpD_kQbM640ofR6hYnBb1xS60nIJNSSznUFqQbwuzWxDmofW9g-8-2FNrcKxmS8wAjUKVQsnpRY15bS5ngf5_u2-VH_J_r5PAE7vXyegJ1Z-RvAn9f1XwDGeUSVt9MYP3Wl098OdpvUNA9WSOZW)\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield.jpeg&w=640&q=75)\n\n`res.get(image)`\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield-no-bg.jpeg&w=640&q=75)\n\n`res.get(removeBg)`\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield-mask.jpeg&w=640&q=75)\n\n`res.get(removeBgMask)`\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield-only-bg.jpeg&w=640&q=75)\n\n`res.get(fillMask)`\n\n[Store & query vectors](/guides/vector-stores \"Store & query vectors\")\n[Masked image generation](/guides/masked-image-generation \"Masked image generation\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "markdown": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nSeparate foreground & background\n\n֍\n\nGenerate an image, remove the background, and fill the foreground\n\nIn this example, we'll create a branching image generation workflow that:\n\n*   Generates an image using GenerateImage\n    \n    Generate an image.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#GenerateImage)\n    \n    GenerateImage( prompt=\"hokusai futuristic supercell spiral cloud with glowing core over turbulent ocean\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n*   Removes the background from the image using RemoveBackground\n    \n    Remove the background from an image and return the foreground segment as a cut-out or a mask.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#RemoveBackground)\n    \n    RemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n*   Generates a masked foreground from the image using RemoveBackground\n    \n    Remove the background from an image and return the foreground segment as a cut-out or a mask.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#RemoveBackground)\n    \n    RemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n    , with `return_mask` enabled\n*   Fills the masked foreground using EraseImage\n    \n    Erase the masked part of an image, e.g. to remove an object by inpainting.\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#EraseImage)\n    \n    EraseImage( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", mask\\_image\\_uri=\"https://media.substrate.run/apple-forest-mask.jpeg\", store=\"hosted\", )\n    \n    Output\n    \n    { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n    \n\nFirst, initialize Substrate:\n\nPython\n\nTypeScript\n\n`   from substrate import (    Substrate,    GenerateImage,    RemoveBackground,    EraseImage,    sb,    )        s = Substrate(api_key=YOUR_API_KEY)            `\n\nCreate and connect four nodes and run them:\n\nPython\n\nTypeScript\n\n`   image = GenerateImage(    prompt=\"a dark red chesterfield leather wing chair in a dark majestic room, pillars, celestial galaxy wallpaper\",    )    bg = RemoveBackground(image_uri=image.future.image_uri)    mask = RemoveBackground(    image_uri=image.future.image_uri,    return_mask=True,    )    erase = EraseImage(    image_uri=image.future.image_uri,    mask_image_uri=mask.future.image_uri,    )    res = s.run(erase)            `\n\n[Run this example](https://explore.substrate.run/s/eNrNlFtv0zAUx7-KZfUxSIOu3dY3JsYugNq1Qkyg6ci1T1MTJ7ZO7HZdle8-OxQWxJAoAmlvORfbv_-5ZMsrq7Dmoy9brhUftWZ_cAJh8GKtr9DwrHXFyDlWSMLjZSlyjG5BeTy35Y5s6XxMEEwJKhihYnKJtUdaaDSKGRR-icTWuspjRGhiumK77FJ8jalaMrK2zJhEk0xhWC6MuNuwtTDGCYfEm4xDvbTBKLDBu-AhN3Yewxs-8hSwyboShgeA80_mbnwYHiVMsbQrPBWyyMmGSnVU6KQKAulkAPR6s1M4n76eXMB4Apdvej2AeMEi-EA4PO6DLQ8-3xzdLHmzJ9dL6A834zMnV_-BawDXi3B9EWarVC7C6K2gFHXxHWUv1FcQPpjJu0Vx-Ih6RqL-ZQT2gzwCdz-HcgbTBJnoYL8LTkC9nVwd3398_wfVv8125zpD_kQbM640ofR6hYnBb1xS60nIJNSSznUFqQbwuzWxDmofW9g-8-2FNrcKxmS8wAjUKVQsnpRY15bS5ngf5_u2-VH_J_r5PAE7vXyegJ1Z-RvAn9f1XwDGeUSVt9MYP3Wl098OdpvUNA9WSOZW)\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield.jpeg&w=640&q=75)\n\n`res.get(image)`\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield-no-bg.jpeg&w=640&q=75)\n\n`res.get(removeBg)`\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield-mask.jpeg&w=640&q=75)\n\n`res.get(removeBgMask)`\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fchesterfield-only-bg.jpeg&w=640&q=75)\n\n`res.get(fillMask)`\n\n[Store & query vectors](/guides/vector-stores \"Store & query vectors\")\n[Masked image generation](/guides/masked-image-generation \"Masked image generation\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "metadata": {
      "ogUrl": "https://docs.substrate.run",
      "title": "Remove Background | Substrate",
      "robots": "index,follow",
      "ogImage": "/og-image-v3.png",
      "ogTitle": "Remove Background | Substrate",
      "sourceURL": "https://docs.substrate.run/guides/remove-background",
      "description": "Substrate",
      "ogDescription": "The platform for compound AI. Powerful SDKs, with batteries included: optimized AI models, vector storage, code interpreter, and agentic control flow. Stop using LangChain.",
      "pageStatusCode": 200,
      "ogLocaleAlternate": []
    },
    "linksOnPage": [
      "https://substrate.run",
      "https://docs.substrate.run/",
      "https://substrate.run/nodes",
      "https://substrate.run/pricing",
      "https://substrate.run/company",
      "https://blog.substrate.run",
      "https://docs.substrate.run/overview/setup",
      "https://docs.substrate.run/overview/connecting",
      "https://docs.substrate.run/overview/storing",
      "https://docs.substrate.run/why",
      "https://docs.substrate.run/changelog",
      "https://docs.substrate.run/guides/extract-and-summarize",
      "https://docs.substrate.run/guides/reimagine-a-room",
      "https://docs.substrate.run/guides/transcription",
      "https://docs.substrate.run/guides/vector-stores",
      "https://docs.substrate.run/guides/remove-background",
      "https://docs.substrate.run/guides/masked-image-generation",
      "https://docs.substrate.run/guides/mixture-of-agents",
      "https://docs.substrate.run/reference/api",
      "https://docs.substrate.run/reference/quick",
      "https://docs.substrate.run/reference/box",
      "https://docs.substrate.run/reference/if",
      "https://docs.substrate.run/reference/run-python",
      "https://docs.substrate.run/reference/streaming",
      "https://docs.substrate.run/reference/external-files",
      "https://docs.substrate.run/reference/external-files/s3",
      "https://docs.substrate.run/reference/versioning",
      "https://docs.substrate.run/reference/legal/terms-of-service",
      "https://docs.substrate.run/reference/legal/privacy-policy",
      "https://docs.substrate.run/reference/legal/usage-policy",
      "https://substrate.run/nodes#GenerateImage",
      "https://substrate.run/nodes#RemoveBackground",
      "https://substrate.run/nodes#EraseImage",
      "https://explore.substrate.run/s/eNrNlFtv0zAUx7-KZfUxSIOu3dY3JsYugNq1Qkyg6ci1T1MTJ7ZO7HZdle8-OxQWxJAoAmlvORfbv_-5ZMsrq7Dmoy9brhUftWZ_cAJh8GKtr9DwrHXFyDlWSMLjZSlyjG5BeTy35Y5s6XxMEEwJKhihYnKJtUdaaDSKGRR-icTWuspjRGhiumK77FJ8jalaMrK2zJhEk0xhWC6MuNuwtTDGCYfEm4xDvbTBKLDBu-AhN3Yewxs-8hSwyboShgeA80_mbnwYHiVMsbQrPBWyyMmGSnVU6KQKAulkAPR6s1M4n76eXMB4Apdvej2AeMEi-EA4PO6DLQ8-3xzdLHmzJ9dL6A834zMnV_-BawDXi3B9EWarVC7C6K2gFHXxHWUv1FcQPpjJu0Vx-Ih6RqL-ZQT2gzwCdz-HcgbTBJnoYL8LTkC9nVwd3398_wfVv8125zpD_kQbM640ofR6hYnBb1xS60nIJNSSznUFqQbwuzWxDmofW9g-8-2FNrcKxmS8wAjUKVQsnpRY15bS5ngf5_u2-VH_J_r5PAE7vXyegJ1Z-RvAn9f1XwDGeUSVt9MYP3Wl098OdpvUNA9WSOZW",
      "https://x.com/substratelabs",
      "https://www.linkedin.com/company/substratelabs",
      "https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA"
    ]
  },
  {
    "content": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nOn This Page\n\n*   [1\\. Generate illusions](#1-generate-illusions)\n    \n*   [2\\. Generate a variation and inpaint](#2-generate-a-variation-and-inpaint)\n    \n\nGuides\n\nMasked image generation\n\n֍\n\nUse a mask to generate images\n\nIn this example, we'll generate a mask from a logo image with\n\nRemoveBackground\n\nRemove the background from an image and return the foreground segment as a cut-out or a mask.\n\nExample\n\n[API Reference](https://substrate.run/nodes#RemoveBackground)\n\nRemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n\nOutput\n\n{ \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n\n, and use that mask to generate variations of the image using two workflows:\n\n1.  Using StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `illusion` method to generate illusions incorporating the mask.\n2.  Using StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `edge` method followed by StableDiffusionXLInpaint\n    \n    Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n    . Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n    \n    StableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    to fill a mask with content and then generate inside the mask.\n\nFirst, initialize Substrate:\n\nPython\n\nTypeScript\n\n`   from substrate import (    Substrate,    RemoveBackground,    StableDiffusionXLControlNet,    StableDiffusionXLInpaint,    )        s = Substrate(api_key=YOUR_API_KEY)            `\n\nHere's the original image:\n\n![original](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Flogo-sq.png&w=640&q=75)\n\n### 1\\. Generate illusions[](#1-generate-illusions)\n\nThis workflow uses\n\nRemoveBackground\n\nRemove the background from an image and return the foreground segment as a cut-out or a mask.\n\nExample\n\n[API Reference](https://substrate.run/nodes#RemoveBackground)\n\nRemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n\nOutput\n\n{ \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n\nto generate a mask, followed by StableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nwith the `illusion` method to generate a two images incorporating the mask into a view of the ocean from above:\n\nPython\n\nTypeScript\n\n`   mask = RemoveBackground(image_uri=\"https://media.substrate.run/logo-sq.png\", return_mask=True)    controlnet = StableDiffusionXLControlNet(    image_uri=mask.future.image_uri,    control_method=\"illusion\",    conditioning_scale=1,    prompt=\"sunlit bright birds-eye view of the ocean, turbulent choppy waves\",    num_images=2,    )    res = s.run(controlnet)            `\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fillusion-1.jpg&w=640&q=75)\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fillusion-2.jpg&w=640&q=75)\n\nExperimenting with different prompts can produce striking results:\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Flogo-atlantis-1.jpg&w=640&q=75)\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Flogo-atlantis-2.jpg&w=640&q=75)\n\n### 2\\. Generate a variation and inpaint[](#2-generate-a-variation-and-inpaint)\n\nThis workflow uses\n\nStableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nto generate a variation of the original, and StableDiffusionXLInpaint\n\nEdit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n. Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n\nStableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nto generate a variation inpainting inside a mask.\n\nPython\n\nTypeScript\n\n`   original = \"https://media.substrate.run/logo-nopad-bg-white.png\"    controlnet = StableDiffusionXLControlNet(    image_uri=original,    control_method=\"depth\",    prompt=\"silver disco ball, 4k\",    conditioning_scale=0.8,    num_images=1,    )    inpaint = StableDiffusionXLInpaint(    image_uri=controlnet.future.outputs[0].image_uri,    mask_image_uri=mask.future.image_uri,    prompt=\"towers in the futuristic ancient solarpunk city of atlantis\",    num_images=1,    )    res = s.run(inpaint)            `\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fex-controlnet.jpeg&w=640&q=75)\n\n`res.get(controlnet)`\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fex-cn-inpaint.webp&w=640&q=75)\n\n`res.get(inpaint)`\n\n[Separate foreground & background](/guides/remove-background \"Separate foreground & background\")\n[Mixture of Agents](/guides/mixture-of-agents \"Mixture of Agents\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "markdown": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nOn This Page\n\n*   [1\\. Generate illusions](#1-generate-illusions)\n    \n*   [2\\. Generate a variation and inpaint](#2-generate-a-variation-and-inpaint)\n    \n\nGuides\n\nMasked image generation\n\n֍\n\nUse a mask to generate images\n\nIn this example, we'll generate a mask from a logo image with\n\nRemoveBackground\n\nRemove the background from an image and return the foreground segment as a cut-out or a mask.\n\nExample\n\n[API Reference](https://substrate.run/nodes#RemoveBackground)\n\nRemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n\nOutput\n\n{ \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n\n, and use that mask to generate variations of the image using two workflows:\n\n1.  Using StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `illusion` method to generate illusions incorporating the mask.\n2.  Using StableDiffusionXLControlNet\n    \n    Generate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n    .\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n    \n    StableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    with the `edge` method followed by StableDiffusionXLInpaint\n    \n    Edit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n    . Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n    \n    Example\n    \n    [API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n    \n    StableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n    \n    Output\n    \n    { \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n    \n    to fill a mask with content and then generate inside the mask.\n\nFirst, initialize Substrate:\n\nPython\n\nTypeScript\n\n`   from substrate import (    Substrate,    RemoveBackground,    StableDiffusionXLControlNet,    StableDiffusionXLInpaint,    )        s = Substrate(api_key=YOUR_API_KEY)            `\n\nHere's the original image:\n\n![original](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Flogo-sq.png&w=640&q=75)\n\n### 1\\. Generate illusions[](#1-generate-illusions)\n\nThis workflow uses\n\nRemoveBackground\n\nRemove the background from an image and return the foreground segment as a cut-out or a mask.\n\nExample\n\n[API Reference](https://substrate.run/nodes#RemoveBackground)\n\nRemoveBackground( image\\_uri=\"https://media.substrate.run/apple-forest.jpeg\", store=\"hosted\", )\n\nOutput\n\n{ \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\" }\n\nto generate a mask, followed by StableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nwith the `illusion` method to generate a two images incorporating the mask into a view of the ocean from above:\n\nPython\n\nTypeScript\n\n`   mask = RemoveBackground(image_uri=\"https://media.substrate.run/logo-sq.png\", return_mask=True)    controlnet = StableDiffusionXLControlNet(    image_uri=mask.future.image_uri,    control_method=\"illusion\",    conditioning_scale=1,    prompt=\"sunlit bright birds-eye view of the ocean, turbulent choppy waves\",    num_images=2,    )    res = s.run(controlnet)            `\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fillusion-1.jpg&w=640&q=75)\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fillusion-2.jpg&w=640&q=75)\n\nExperimenting with different prompts can produce striking results:\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Flogo-atlantis-1.jpg&w=640&q=75)\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Flogo-atlantis-2.jpg&w=640&q=75)\n\n### 2\\. Generate a variation and inpaint[](#2-generate-a-variation-and-inpaint)\n\nThis workflow uses\n\nStableDiffusionXLControlNet\n\nGenerate an image with generation structured by an input image, using Stable Diffusion XL with [ControlNet](https://arxiv.org/abs/2302.05543)\n.\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLControlNet)\n\nStableDiffusionXLControlNet( image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"the futuristic solarpunk city of atlantis at sunset, cinematic bokeh HD\", control\\_method=\"illusion\", conditioning\\_scale=1.0, strength=1.0, store=\"hosted\", num\\_images=2, seeds=\\[ 1607226, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607266 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nto generate a variation of the original, and StableDiffusionXLInpaint\n\nEdit an image using [Stable Diffusion XL](https://arxiv.org/abs/2307.01952)\n. Supports inpainting (edit part of the image with a mask) and image-to-image (edit the full image).\n\nExample\n\n[API Reference](https://substrate.run/nodes#StableDiffusionXLInpaint)\n\nStableDiffusionXLInpaint( image\\_uri=\"https://media.substrate.run/docs-klimt-park.jpg\", mask\\_image\\_uri=\"https://media.substrate.run/spiral-logo.jpeg\", prompt=\"large tropical colorful bright birds in a jungle, high resolution oil painting\", negative\\_prompt=\"dark, cartoon, anime\", strength=0.8, num\\_images=2, store=\"hosted\", seeds=\\[ 1607280, 1720395, \\], )\n\nOutput\n\n{ \"outputs\": \\[ { \"image\\_uri\": \"https://assets.substrate.run/84848484.jpg\", \"seed\": 1607326 }, { \"image\\_uri\": \"https://assets.substrate.run/48484848.jpg\", \"seed\": 1720398 } \\] }\n\nto generate a variation inpainting inside a mask.\n\nPython\n\nTypeScript\n\n`   original = \"https://media.substrate.run/logo-nopad-bg-white.png\"    controlnet = StableDiffusionXLControlNet(    image_uri=original,    control_method=\"depth\",    prompt=\"silver disco ball, 4k\",    conditioning_scale=0.8,    num_images=1,    )    inpaint = StableDiffusionXLInpaint(    image_uri=controlnet.future.outputs[0].image_uri,    mask_image_uri=mask.future.image_uri,    prompt=\"towers in the futuristic ancient solarpunk city of atlantis\",    num_images=1,    )    res = s.run(inpaint)            `\n\n![image](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fex-controlnet.jpeg&w=640&q=75)\n\n`res.get(controlnet)`\n\n![no background](https://docs.substrate.run/_next/image?url=https%3A%2F%2Fmedia.substrate.run%2Fex-cn-inpaint.webp&w=640&q=75)\n\n`res.get(inpaint)`\n\n[Separate foreground & background](/guides/remove-background \"Separate foreground & background\")\n[Mixture of Agents](/guides/mixture-of-agents \"Mixture of Agents\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "metadata": {
      "ogUrl": "https://docs.substrate.run",
      "title": "Masked Image Generation | Substrate",
      "robots": "index,follow",
      "ogImage": "/og-image-v3.png",
      "ogTitle": "Masked Image Generation | Substrate",
      "sourceURL": "https://docs.substrate.run/guides/masked-image-generation",
      "description": "Substrate",
      "ogDescription": "The platform for compound AI. Powerful SDKs, with batteries included: optimized AI models, vector storage, code interpreter, and agentic control flow. Stop using LangChain.",
      "pageStatusCode": 200,
      "ogLocaleAlternate": []
    },
    "linksOnPage": [
      "https://substrate.run",
      "https://docs.substrate.run/",
      "https://substrate.run/nodes",
      "https://substrate.run/pricing",
      "https://substrate.run/company",
      "https://blog.substrate.run",
      "https://docs.substrate.run/overview/setup",
      "https://docs.substrate.run/overview/connecting",
      "https://docs.substrate.run/overview/storing",
      "https://docs.substrate.run/why",
      "https://docs.substrate.run/changelog",
      "https://docs.substrate.run/guides/extract-and-summarize",
      "https://docs.substrate.run/guides/reimagine-a-room",
      "https://docs.substrate.run/guides/transcription",
      "https://docs.substrate.run/guides/vector-stores",
      "https://docs.substrate.run/guides/remove-background",
      "https://docs.substrate.run/guides/masked-image-generation",
      "https://docs.substrate.run/guides/mixture-of-agents",
      "https://docs.substrate.run/reference/api",
      "https://docs.substrate.run/reference/quick",
      "https://docs.substrate.run/reference/box",
      "https://docs.substrate.run/reference/if",
      "https://docs.substrate.run/reference/run-python",
      "https://docs.substrate.run/reference/streaming",
      "https://docs.substrate.run/reference/external-files",
      "https://docs.substrate.run/reference/external-files/s3",
      "https://docs.substrate.run/reference/versioning",
      "https://docs.substrate.run/reference/legal/terms-of-service",
      "https://docs.substrate.run/reference/legal/privacy-policy",
      "https://docs.substrate.run/reference/legal/usage-policy",
      "https://substrate.run/nodes#RemoveBackground",
      "https://arxiv.org/abs/2302.05543",
      "https://substrate.run/nodes#StableDiffusionXLControlNet",
      "https://arxiv.org/abs/2307.01952",
      "https://substrate.run/nodes#StableDiffusionXLInpaint",
      "https://x.com/substratelabs",
      "https://www.linkedin.com/company/substratelabs",
      "https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA"
    ]
  },
  {
    "content": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\nCTRL K\n\nCTRL K\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nMixture of Agents\n\n֍\n\nLearn how to implement Mixture of Agents\n\nLanguage models can perform better on tasks when given the opportunity to reflect on a proposed response. \"Mixture of Agents\" is a pattern (coined [by Together AI (opens in a new tab)](https://www.together.ai/blog/together-moa)\n) in which multiple different LLMs propose responses, and subsequent LLM steps evaluate and synthesize those responses into a single improved response.\n\n`propose`\n\nComputeText\n\n`propose`\n\nComputeText\n\n`propose`\n\nComputeText\n\n`evaluate`\n\nComputeText\n\n`summarize`\n\nComputeText\n\nPress enter or space to select a node.You can then use the arrow keys to move the node around. Press delete to remove it and escape to cancel.\n\nPress enter or space to select an edge. You can then press delete to remove it or escape to cancel.\n\nThis pattern is simple to implement with Substrate, automatically parallelized, and easy to extend.\n\nTypeScript\n\nPython\n\n``   const substrate = new Substrate({ apiKey: SUBSTRATE_API_KEY });        const prompt = \"write me a summary of don quixote\";    const mist = new ComputeText({ prompt: prompt, model: \"Mistral7BInstruct\" });    const llama = new ComputeText({ prompt: prompt, model: \"Llama3Instruct8B\" });    const mixt = new ComputeText({ prompt: prompt, model: \"Mixtral8x7BInstruct\" });    const reasoning = new ComputeText({    prompt: sb.interpolate`Reason about the strengths and weaknesses of each response. Explain which elements from each response are superior.    PROMPT: ${prompt}    CANDIDATE RESPONSES:    1) ${mist.future.text}    2) ${llama.future.text}    3) ${mixt.future.text}`,    });    const answer = new ComputeText({    prompt: sb.interpolate`Come up with one detailed, comprehensive, unified response using the best parts of the candidate responses, based on the evaluation. Return only the response, do not reveal the process (do not say candidate response or evaluation).    PROMPT: ${prompt}    CANDIDATE RESPONSES:    1) ${mist.future.text}    2) ${llama.future.text}    3) ${mixt.future.text}    EVALUATION: ${reasoning.future.text}`,    });        const res = await substrate.run(answer);    console.log(res.get(answer).text);            ``\n\n[Masked image generation](/guides/masked-image-generation \"Masked image generation\")\n[API design](/reference/api \"API design\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "markdown": "[](https://substrate.run)\n\n[Docs](/)\n\n[Nodes](https://substrate.run/nodes)\n\n[Pricing](https://substrate.run/pricing)\n\n[Company](https://substrate.run/company)\n\n[Blog](https://blog.substrate.run)\n\n...\n\nCTRL K\n\nCTRL K\n\n*   [Introduction](/)\n    \n*   Overview\n    \n    *   [Get started](/overview/setup)\n        \n    *   [Connect nodes](/overview/connecting)\n        \n    *   [Store outputs](/overview/storing)\n        \n    \n*   [Why Substrate?](/why)\n    \n*   [Changelog](/changelog)\n    \n*   Guides\n    \n    *   [Extract and summarize Hacker News comments](/guides/extract-and-summarize)\n        \n    *   [Reimagine a room](/guides/reimagine-a-room)\n        \n    *   [Transcribe audio & video](/guides/transcription)\n        \n    *   [Store & query vectors](/guides/vector-stores)\n        \n    *   [Separate foreground & background](/guides/remove-background)\n        \n    *   [Masked image generation](/guides/masked-image-generation)\n        \n    *   [Mixture of Agents](/guides/mixture-of-agents)\n        \n    \n*   Reference\n    \n    *   [API design](/reference/api)\n        \n    *   [Quick reference](/reference/quick)\n        \n    *   [Box](/reference/box)\n        \n    *   [If](/reference/if)\n        \n    *   [RunPython](/reference/run-python)\n        \n    *   [Streaming](/reference/streaming)\n        \n    *   [External files](/reference/external-files)\n        \n        *   [Amazon S3](/reference/external-files/s3)\n            \n        \n    *   [Versioning](/reference/versioning)\n        \n    *   Legal\n        \n        *   [Terms of Service](/reference/legal/terms-of-service)\n            \n        *   [Privacy Policy](/reference/legal/privacy-policy)\n            \n        *   [Usage Policy](/reference/legal/usage-policy)\n            \n        \n    \n\nGuides\n\nMixture of Agents\n\n֍\n\nLearn how to implement Mixture of Agents\n\nLanguage models can perform better on tasks when given the opportunity to reflect on a proposed response. \"Mixture of Agents\" is a pattern (coined [by Together AI (opens in a new tab)](https://www.together.ai/blog/together-moa)\n) in which multiple different LLMs propose responses, and subsequent LLM steps evaluate and synthesize those responses into a single improved response.\n\n`propose`\n\nComputeText\n\n`propose`\n\nComputeText\n\n`propose`\n\nComputeText\n\n`evaluate`\n\nComputeText\n\n`summarize`\n\nComputeText\n\nPress enter or space to select a node.You can then use the arrow keys to move the node around. Press delete to remove it and escape to cancel.\n\nPress enter or space to select an edge. You can then press delete to remove it or escape to cancel.\n\nThis pattern is simple to implement with Substrate, automatically parallelized, and easy to extend.\n\nTypeScript\n\nPython\n\n``   const substrate = new Substrate({ apiKey: SUBSTRATE_API_KEY });        const prompt = \"write me a summary of don quixote\";    const mist = new ComputeText({ prompt: prompt, model: \"Mistral7BInstruct\" });    const llama = new ComputeText({ prompt: prompt, model: \"Llama3Instruct8B\" });    const mixt = new ComputeText({ prompt: prompt, model: \"Mixtral8x7BInstruct\" });    const reasoning = new ComputeText({    prompt: sb.interpolate`Reason about the strengths and weaknesses of each response. Explain which elements from each response are superior.    PROMPT: ${prompt}    CANDIDATE RESPONSES:    1) ${mist.future.text}    2) ${llama.future.text}    3) ${mixt.future.text}`,    });    const answer = new ComputeText({    prompt: sb.interpolate`Come up with one detailed, comprehensive, unified response using the best parts of the candidate responses, based on the evaluation. Return only the response, do not reveal the process (do not say candidate response or evaluation).    PROMPT: ${prompt}    CANDIDATE RESPONSES:    1) ${mist.future.text}    2) ${llama.future.text}    3) ${mixt.future.text}    EVALUATION: ${reasoning.future.text}`,    });        const res = await substrate.run(answer);    console.log(res.get(answer).text);            ``\n\n[Masked image generation](/guides/masked-image-generation \"Masked image generation\")\n[API design](/reference/api \"API design\")\n\n[© 2023-2024 Substrate Labs Inc.](https://substrate.run)\n\n[Twitter](https://x.com/substratelabs)\n\n[LinkedIn](https://www.linkedin.com/company/substratelabs)\n\n[Slack Community](https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA)",
    "metadata": {
      "ogUrl": "https://docs.substrate.run",
      "title": "Mixture of Agents | Substrate",
      "robots": "index,follow",
      "ogImage": "/og-image-v3.png",
      "ogTitle": "Mixture of Agents | Substrate",
      "sourceURL": "https://docs.substrate.run/guides/mixture-of-agents",
      "description": "Substrate",
      "ogDescription": "The platform for compound AI. Powerful SDKs, with batteries included: optimized AI models, vector storage, code interpreter, and agentic control flow. Stop using LangChain.",
      "pageStatusCode": 200,
      "ogLocaleAlternate": []
    },
    "linksOnPage": [
      "https://substrate.run",
      "https://docs.substrate.run/",
      "https://substrate.run/nodes",
      "https://substrate.run/pricing",
      "https://substrate.run/company",
      "https://blog.substrate.run",
      "https://docs.substrate.run/overview/setup",
      "https://docs.substrate.run/overview/connecting",
      "https://docs.substrate.run/overview/storing",
      "https://docs.substrate.run/why",
      "https://docs.substrate.run/changelog",
      "https://docs.substrate.run/guides/extract-and-summarize",
      "https://docs.substrate.run/guides/reimagine-a-room",
      "https://docs.substrate.run/guides/transcription",
      "https://docs.substrate.run/guides/vector-stores",
      "https://docs.substrate.run/guides/remove-background",
      "https://docs.substrate.run/guides/masked-image-generation",
      "https://docs.substrate.run/guides/mixture-of-agents",
      "https://docs.substrate.run/reference/api",
      "https://docs.substrate.run/reference/quick",
      "https://docs.substrate.run/reference/box",
      "https://docs.substrate.run/reference/if",
      "https://docs.substrate.run/reference/run-python",
      "https://docs.substrate.run/reference/streaming",
      "https://docs.substrate.run/reference/external-files",
      "https://docs.substrate.run/reference/external-files/s3",
      "https://docs.substrate.run/reference/versioning",
      "https://docs.substrate.run/reference/legal/terms-of-service",
      "https://docs.substrate.run/reference/legal/privacy-policy",
      "https://docs.substrate.run/reference/legal/usage-policy",
      "https://www.together.ai/blog/together-moa",
      "https://x.com/substratelabs",
      "https://www.linkedin.com/company/substratelabs",
      "https://join.slack.com/t/substratecommunity/shared_invite/zt-2jd8w6b7n-b0qE5QWV7rsClGglHeu_rA"
    ]
  }
]